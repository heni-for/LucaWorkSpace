/**
 * LUCA Background Voice Assistant
 * Always listening for "Ahla Beleh" wake word
 * Understands and speaks in Tunisian Derja
 */

import { cloudTTS } from './cloud-tts';

export type LucaCommand = {
  intent: string;
  action: string;
  parameters?: Record<string, any>;
  response: string;
};

export type LucaMode = 'idle' | 'email' | 'meeting' | 'note' | 'task' | 'search';

export class LucaVoiceAssistant {
  private recognition: any = null;
  private isListening: boolean = false;
  private onWakeWordCallback?: () => void;
  private onCommandCallback?: (command: string) => void;
  private onResponseCallback?: (response: string) => void;
  private onStatusChangeCallback?: (status: 'idle' | 'listening' | 'processing' | 'speaking') => void;
  private lastWakeWordTime: number = 0;
  private wakeWordCooldownMs: number = 1500; // Reduced to 1.5s for faster response
  private isBusy: boolean = false; // Prevent overlapping commands
  private voicesLoaded: boolean = false;
  private currentMode: LucaMode = 'idle'; // Track what mode LUCA is in
  private continuousMode: boolean = true; // Always keep listening
  
  // ğŸ¯ ChatGPT-style streaming variables
  private silenceTimer: any = null;
  private lastSpeechTime: number = 0;
  private silenceThreshold: number = 1200; // 1.2s silence = end of phrase
  private currentInterimText: string = '';
  private isProcessingCommand: boolean = false;

  constructor() {
    this.setupRecognition();
    this.loadVoices();
  }

  private loadVoices(): void {
    if (typeof window === 'undefined' || !window.speechSynthesis) return;

    // Function to check and log voices
    const checkVoices = () => {
      const voices = window.speechSynthesis.getVoices();
      if (voices.length > 0 && !this.voicesLoaded) {
        this.voicesLoaded = true;
        console.log('âœ… Voices loaded:', voices.length);
        console.log('ğŸ™ï¸ Arabic voices:', voices.filter(v => v.lang.startsWith('ar')).map(v => v.name));
      }
      return voices;
    };

    // Try loading immediately
    checkVoices();

    // Also listen for voices changed event
    window.speechSynthesis.onvoiceschanged = () => {
      checkVoices();
    };

    // Force trigger voice loading
    setTimeout(() => {
      window.speechSynthesis.getVoices();
    }, 100);
  }

  private setupRecognition() {
    if (typeof window === 'undefined') return;

    const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
    
    if (!SpeechRecognition) {
      console.warn('Speech recognition not supported');
      return;
    }

    try {
      this.recognition = new SpeechRecognition();
      
      // ğŸ¯ PROFESSIONAL SETTINGS for BEST accuracy
      this.recognition.lang = 'ar-SA'; // Standard Arabic (better recognition than ar-TN)
      this.recognition.continuous = true; // ğŸ” CONTINUOUS MODE
      this.recognition.interimResults = true; // Show real-time results
      this.recognition.maxAlternatives = 5; // More alternatives for better accuracy
      
      // âœ¨ BOOST ACCURACY
      if ('grammars' in this.recognition) {
        // Add grammar hints for better recognition
        console.log('âœ… Grammar support available');
      }

      this.recognition.onresult = this.handleSpeechResult.bind(this);
      this.recognition.onerror = this.handleError.bind(this);
      this.recognition.onend = this.handleEnd.bind(this);
      
      // ğŸ¯ Professional audio event tracking (ChatGPT-style)
      this.recognition.onaudiostart = () => {
        console.log('ğŸ¤ Audio input started');
        this.lastSpeechTime = Date.now();
      };
      
      this.recognition.onaudioend = () => {
        console.log('ğŸ¤ Audio input ended');
      };
      
      this.recognition.onsoundstart = () => {
        console.log('ğŸ”Š Sound detected');
        this.lastSpeechTime = Date.now();
        this.clearSilenceTimer();
      };
      
      this.recognition.onsoundend = () => {
        console.log('ğŸ”‡ Sound ended - starting silence detection');
        this.startSilenceTimer();
      };
      
      this.recognition.onspeechstart = () => {
        console.log('ğŸ—£ï¸ Speech detected');
        this.lastSpeechTime = Date.now();
        this.clearSilenceTimer();
      };
      
      this.recognition.onspeechend = () => {
        console.log('ğŸ—£ï¸ Speech ended - waiting for finalization');
      };

      console.log('ğŸš€ LUCA Voice Assistant initialized - PROFESSIONAL MODE');
      console.log('ğŸ¯ Language: ar-SA (Standard Arabic)');
      console.log('ğŸ¯ Max alternatives: 5');
      console.log('ğŸ¯ Continuous: true');
    } catch (error) {
      console.error('Failed to setup speech recognition:', error);
    }
  }

  // ğŸ”‡ Silence detection timer (ChatGPT-style)
  private clearSilenceTimer(): void {
    if (this.silenceTimer) {
      clearTimeout(this.silenceTimer);
      this.silenceTimer = null;
    }
  }

  private startSilenceTimer(): void {
    this.clearSilenceTimer();
    
    // After silence threshold, we know user finished speaking
    this.silenceTimer = setTimeout(() => {
      const timeSinceSpeech = Date.now() - this.lastSpeechTime;
      console.log(`ğŸ”‡ Silence detected (${timeSinceSpeech}ms) - user likely finished speaking`);
      
      // Could trigger processing here if needed
      if (this.currentInterimText && !this.isProcessingCommand) {
        console.log('ğŸ’¡ Could fast-track processing here for better UX');
      }
    }, this.silenceThreshold);
  }

  private async handleSpeechResult(event: any) {
    try {
      const results = event.results[event.results.length - 1];
      const isFinal = results.isFinal;
      
      // ğŸ¯ GET BEST ALTERNATIVE with highest confidence (analyze all 5 alternatives)
      let bestTranscript = '';
      let bestConfidence = 0;
      let allAlternatives: string[] = [];
      
      for (let i = 0; i < results.length; i++) {
        const alternative = results[i];
        const confidence = alternative.confidence || 0;
        allAlternatives.push(`${alternative.transcript} (${Math.round(confidence * 100)}%)`);
        
        if (confidence > bestConfidence) {
          bestConfidence = confidence;
          bestTranscript = alternative.transcript;
        }
      }
      
      // Use best alternative or fallback to first one
      const transcript = (bestTranscript || results[0].transcript).toLowerCase().trim();
      const confidencePercent = Math.round(bestConfidence * 100);
      
      // Update interim text for silence detection
      if (!isFinal) {
        this.currentInterimText = transcript;
        this.lastSpeechTime = Date.now();
      }
      
      // Always log what we hear with confidence + alternatives
      if (isFinal && allAlternatives.length > 1) {
        console.log(`ğŸ¤ LUCA HEARD (FINAL) [${confidencePercent}% confidence]:`, `"${transcript}"`);
        console.log(`ğŸ“‹ All ${allAlternatives.length} alternatives:`, allAlternatives.join(' | '));
      } else {
        console.log(`ğŸ¤ LUCA HEARD (${isFinal ? 'FINAL' : 'interim'}) [${confidencePercent}% confidence]:`, `"${transcript}"`);
      }
      
      // Only process FINAL results to avoid partial matches
      if (!isFinal) {
        console.log('â­ï¸ Skipping interim result, waiting for final...');
        return;
      }
      
      // Clear silence timer on final result
      this.clearSilenceTimer();
      this.currentInterimText = '';
      
      // âš ï¸ Low confidence warning with alternatives
      if (isFinal && bestConfidence < 0.7) {
        console.warn(`âš ï¸ Low confidence (${confidencePercent}%) - may be inaccurate`);
        if (allAlternatives.length > 1) {
          console.log(`ğŸ’¡ Consider these alternatives:`, allAlternatives.slice(0, 3));
        }
      }
      
      // Update last command for UI
      if (this.onCommandCallback) {
        this.onCommandCallback(transcript);
      }

      // Check for wake words (including pronunciation variations)
      const wakeWords = [
        'ahla beleh', 'ahla balah', 'ahla blek', 'ahla belek',
        'luca', 'louca', 'luka', 'lucas', 'luke',
        'ya luca', 'ÙŠØ§ Ù„ÙˆÙƒØ§', 'Ù„ÙˆÙƒØ§', 'Ù„ÙˆÙƒØ©', 'Ù„ÙˆÙƒ', 'Ù„ÙˆÙƒÙ‡',
        'hey luca', 'ok luca', 'yo luca'
      ];

      const hasWakeWord = wakeWords.some(wake => transcript.includes(wake));

      if (hasWakeWord) {
        // Check cooldown to prevent rapid re-triggering
        const now = Date.now();
        if (now - this.lastWakeWordTime < this.wakeWordCooldownMs) {
          console.log('â³ Cooldown active, ignoring duplicate wake word');
          return;
        }
        
        // Check if already processing
        if (this.isBusy) {
          console.log('â³ LUCA is busy, ignoring...');
          return;
        }
        
        this.lastWakeWordTime = now;
        this.isBusy = true;
        
        console.log('âœ…âœ…âœ… WAKE WORD DETECTED! âœ…âœ…âœ…');
        console.log('ğŸ”Š LUCA will now respond...');
        
        if (this.onWakeWordCallback) {
          this.onWakeWordCallback();
        }

        // Extract command (everything after wake word)
        let command = '';
        
        // Find which wake word was used
        let usedWakeWord = '';
        for (const wake of wakeWords) {
          if (transcript.includes(wake)) {
            usedWakeWord = wake;
            break;
          }
        }
        
        if (usedWakeWord) {
          // Find the position of the wake word
          const wakeIndex = transcript.indexOf(usedWakeWord);
          const afterWake = transcript.substring(wakeIndex + usedWakeWord.length).trim();
          command = afterWake;
          
          console.log('ğŸ“ Wake word used:', usedWakeWord);
          console.log('ğŸ“‹ Command extracted:', command || '(none)');
        }

        try {
          // Choose response based on wake word used
          let response = 'Ø£Ù†ÙŠ Ù†Ø³Ù…Ø¹ ÙÙŠÙƒ'; // Default: "ani nasma3 fyk" - I'm listening to you
          
          // If they said "ahla" in any form, respond with "ahla winek"
          if (transcript.includes('ahla') || transcript.includes('Ø£Ù‡Ù„Ø§')) {
            response = 'Ø£Ù‡Ù„Ø§ ÙˆÙŠÙ†Ùƒ'; // "ahla winek" - Hello, how are you
            console.log('ğŸ‘‹ Detected "ahla" greeting, responding with "ahla winek"');
          }
          
          console.log('ğŸ—£ï¸ Speaking wake word response:', response);
          await this.speak(response);
          
          if (command) {
            console.log('ğŸ“‹ Command extracted:', command);
            // Wait a bit before processing to let wake response finish
            await new Promise(resolve => setTimeout(resolve, 500));
            // Process the command
            await this.processCommand(command);
          } else {
            console.log('â„¹ï¸ No command after wake word - just greeting');
          }
        } finally {
          this.isBusy = false;
        }
      } else {
        console.log('â„¹ï¸ Not a wake word, ignoring...');
      }
    } catch (error) {
      console.error('âŒ Error handling speech:', error);
    }
  }

  private handleError(event: any) {
    const errorType = event.error;
    
    switch (errorType) {
      case 'no-speech':
        console.log('ğŸ”‡ No speech detected (silence)');
        break;
      case 'audio-capture':
        console.error('âŒ MICROPHONE ERROR: No microphone found or not working');
        alert('ğŸ¤ Microphone error! Please check your microphone connection.');
        break;
      case 'not-allowed':
        console.error('âŒ PERMISSION DENIED: Microphone access blocked');
        alert('ğŸ¤ Please allow microphone access in your browser settings!');
        break;
      case 'network':
        console.warn('âš ï¸ Network error - speech recognition requires internet');
        break;
      case 'aborted':
        console.log('ğŸ›‘ Recognition aborted');
        break;
      case 'bad-grammar':
        console.error('âŒ Grammar error in speech recognition');
        break;
      default:
        console.warn('âš ï¸ LUCA speech error:', errorType);
    }
  }

  private handleEnd() {
    // ğŸ” Auto-restart to keep listening (CONTINUOUS MODE - ChatGPT style)
    if (this.isListening && this.continuousMode) {
      console.log('ğŸ” Recognition ended, restarting immediately (ChatGPT-style)...');
      
      // Restart IMMEDIATELY (no delay) for seamless experience
      setTimeout(() => {
        if (this.recognition && this.isListening) {
          try {
            this.recognition.start();
            console.log('âœ… Recognition restarted - ready for next command!');
          } catch (error) {
            console.log('â„¹ï¸ Recognition already running');
          }
        }
      }, 50); // Minimal delay (50ms) for instant restart
    } else {
      console.log('ğŸ›‘ Recognition ended, not restarting');
    }
  }

  // ğŸ¯ Main command processing with continuous listening
  // ğŸ¯ ChatGPT-style command processing with streaming feel
  public async processCommand(command: string): Promise<void> {
    // Prevent overlapping processing
    if (this.isProcessingCommand) {
      console.log('â³ Already processing a command, please wait...');
      return;
    }

    this.isProcessingCommand = true;
    const processingStartTime = Date.now();
    
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    console.log('ğŸ§  Processing command:', command);
    console.log('ğŸ­ Current mode:', this.currentMode);
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    
    if (this.onStatusChangeCallback) {
      this.onStatusChangeCallback('processing');
    }

    try {
      await this.analyzeAndExecuteCommand(command);
      
      const processingTime = Date.now() - processingStartTime;
      console.log(`âš¡ Command processed in ${processingTime}ms`);
    } catch (error) {
      console.error('âŒ Command processing error:', error);
      console.log('ğŸ—£ï¸ Speaking fallback message...');
      await this.speak('Ù…Ø¹Ù„ÙŠØ´ØŒ Ù…Ø§ ÙÙ‡Ù…ØªØ´. Ø¹Ø§ÙˆØ¯ Ù…Ù† ÙØ¶Ù„Ùƒ.'); // Sorry, didn't understand
    } finally {
      this.isProcessingCommand = false;
      
      // ğŸ” Keep listening (continuous mode) - ChatGPT style
      console.log('ğŸ” Continuing to listen for more commands...');
      console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
      
      if (this.onStatusChangeCallback) {
        this.onStatusChangeCallback('listening');
      }
    }
  }

  // ğŸ§© AI-POWERED INTENT ANALYSIS - Let AI figure out what user wants!
  private async analyzeAndExecuteCommand(text: string): Promise<void> {
    const lowerCmd = text.toLowerCase();
    let response = '';
    let action = 'unknown';
    
    // âš¡ DIRECT MATCHING for simple common commands (FAST - no AI needed)
    
    // ğŸ›‘ STOP
    if (lowerCmd.includes('stop') || lowerCmd.includes('Ø®Ù„Ø§Øµ') || lowerCmd.includes('khallas') || lowerCmd.includes('ÙˆÙ‚Ù')) {
      response = 'Ø¨Ø§ÙŠ Ø¨Ø§ÙŠØŒ Ù†Ù„Ù‚Ø§Ùƒ Ù‚Ø±ÙŠØ¨!';
      action = 'stop_listening';
      console.log('ğŸ›‘ STOP - direct match');
      await this.speak(response);
      this.continuousMode = false;
      this.stop();
      return;
    }
    
    // ğŸ• TIME - Direct (most common)
    else if (lowerCmd.includes('Ù‚Ø¯Ø§Ø´') || lowerCmd.includes('ÙˆÙ‚Øª') || lowerCmd.includes('Ø³Ø§Ø¹Ø©') || lowerCmd.includes('time') || lowerCmd.includes('heure') || lowerCmd.includes('clock')) {
      const now = new Date();
      const hours = now.getHours();
      const minutes = now.getMinutes();
      response = `Ø§Ù„ÙˆÙ‚Øª ØªÙˆ ${hours}:${minutes.toString().padStart(2, '0')}`;
      action = 'tell_time';
      console.log('â° TIME - direct match');
    }
    
    // ğŸ“§ EMAIL - Direct keyword check
    else if (lowerCmd.includes('Ø§ÙŠÙ…ÙŠÙ„') || lowerCmd.includes('Ø¥ÙŠÙ…ÙŠÙ„') || lowerCmd.includes('Ù…ÙŠÙ„') || lowerCmd.includes('Ø¨Ø±ÙŠØ¯') || lowerCmd.includes('mail') || lowerCmd.includes('email') || lowerCmd.includes('gmail')) {
      response = 'Ø­Ø§Ø¶Ø±ØŒ Ù†Ø­Ù„Ù‘Ùƒ Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„Ø§Øª ØªÙˆ.';
      action = 'open_mail';
      console.log('ğŸ“§ EMAIL - direct match');
    }
    
    // ğŸ“Š DASHBOARD - Direct keyword check
    else if (lowerCmd.includes('Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯') || lowerCmd.includes('Ø¯ÙŠØ³Ø¨ÙˆØ±Ø¯') || lowerCmd.includes('Ø¯Ø§Ø´') || lowerCmd.includes('dashboard') || lowerCmd.includes('dash') || lowerCmd.includes('Ù„ÙˆØ­Ø©') || lowerCmd.includes('home')) {
      response = 'Ø­Ø§Ø¶Ø±ØŒ Ù†Ø­Ù„Ù‘Ùƒ dashboard ØªÙˆ.';
      action = 'open_dashboard';
      console.log('ğŸ“Š DASHBOARD - direct match');
    }
    
    // ğŸ“… CALENDAR - Direct keyword check
    else if (lowerCmd.includes('ÙƒØ§Ù„Ù†Ø¯Ø±ÙŠ') || lowerCmd.includes('ÙƒØ§Ù„Ù†Ø¯') || lowerCmd.includes('calendrier') || lowerCmd.includes('calendar') || lowerCmd.includes('agenda') || lowerCmd.includes('Ù…ÙˆØ¹Ø¯') || lowerCmd.includes('ØªÙ‚ÙˆÙŠÙ…')) {
      response = 'Ø­Ø§Ø¶Ø±ØŒ Ù†ÙˆØ±Ù‘ÙŠÙƒ Ø§Ù„ÙƒØ§Ù„Ù†Ø¯Ø±ÙŠ.';
      action = 'open_calendar';
      console.log('ğŸ“… CALENDAR - direct match');
    }
    
    // âœ… TASKS - Direct keyword check
    else if (lowerCmd.includes('ØªØ³Ùƒ') || lowerCmd.includes('Ù…Ù‡Ø§Ù…') || lowerCmd.includes('Ù…Ù‡Ù…Ø©') || lowerCmd.includes('task') || lowerCmd.includes('todo') || lowerCmd.includes('tache')) {
      response = 'Ù†ÙˆØ±Ù‘ÙŠÙƒ Ø§Ù„ØªØ³ÙƒØ§Øª.';
      action = 'open_tasks';
      console.log('âœ… TASKS - direct match');
    }
    
    // ğŸ“ NOTES - Direct keyword check  
    else if (lowerCmd.includes('Ù†ÙˆØª') || lowerCmd.includes('Ù…Ù„Ø§Ø­Ø¸') || lowerCmd.includes('Ù…Ø°ÙƒØ±') || lowerCmd.includes('note')) {
      response = 'Ø­Ø§Ø¶Ø±ØŒ Ù†Ø­Ù„Ù‘Ùƒ notes.';
      action = 'open_notes';
      console.log('ğŸ“ NOTES - direct match');
    }
    
    // ğŸ“š EDUCATION - Direct keyword check
    else if (lowerCmd.includes('Ø¯Ø±Ø§Ø³Ø©') || lowerCmd.includes('ØªØ¹Ù„ÙŠÙ…') || lowerCmd.includes('Ø¯Ø±Ø³') || lowerCmd.includes('education') || lowerCmd.includes('Ã©ducation') || lowerCmd.includes('cours')) {
      response = 'Ø­Ø§Ø¶Ø±ØŒ Ù†Ø­Ù„Ù‘Ùƒ Ã©ducation ØªÙˆ.';
      action = 'open_education';
      console.log('ğŸ“š EDUCATION - direct match');
    }
    
    // ğŸ‘¥ MEETINGS - Direct keyword check
    else if (lowerCmd.includes('Ø§Ø¬ØªÙ…Ø§Ø¹') || lowerCmd.includes('Ù…ÙŠØªÙŠÙ†Øº') || lowerCmd.includes('Ù„Ù‚Ø§Ø¡') || lowerCmd.includes('meeting') || lowerCmd.includes('rÃ©union')) {
      response = 'Ù†Ø­Ù„Ù‘Ùƒ ØµÙØ­Ø© Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹Ø§Øª.';
      action = 'open_meetings';
      console.log('ğŸ‘¥ MEETINGS - direct match');
    }
    
    // ğŸ‘¥ TEAM - Direct keyword check
    else if (lowerCmd.includes('ÙØ±ÙŠÙ‚') || lowerCmd.includes('Ø²Ù…Ù„Ø§Ø¡') || lowerCmd.includes('team') || lowerCmd.includes('Ã©quipe')) {
      response = 'Ù†Ø­Ù„Ù‘Ùƒ ØµÙØ­Ø© Ø§Ù„ÙØ±ÙŠÙ‚.';
      action = 'open_team';
      console.log('ğŸ‘¥ TEAM - direct match');
    }
    
    // ğŸ“ PROJECTS - Direct keyword check
    else if (lowerCmd.includes('Ù…Ø´Ø±ÙˆØ¹') || lowerCmd.includes('Ù…Ø´Ø§Ø±ÙŠØ¹') || lowerCmd.includes('Ø¨Ø±ÙˆØ¬ÙŠÙ‡') || lowerCmd.includes('project')) {
      response = 'Ù†Ø­Ù„Ù‘Ùƒ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹.';
      action = 'open_projects';
      console.log('ğŸ“ PROJECTS - direct match');
    }
    
    // â“ HELP - Direct
    else if (lowerCmd.includes('help') || lowerCmd.includes('aide') || lowerCmd.includes('Ù…Ø³Ø§Ø¹Ø¯Ø©') || lowerCmd.includes('Ø¹Ø§ÙˆÙ†ÙŠ')) {
      response = 'Ù†Ø¬Ù… Ù†Ø­Ù„Ù‘Ùƒ: emailØŒ dashboardØŒ calendarØŒ tasksØŒ notesØŒ education. Ù‚Ù„Ù‘ÙŠ Ø´Ù†Ùˆ ØªØ­Ø¨.';
      action = 'help';
      console.log('â“ HELP - direct match');
    }
    
    // ğŸ¤– USE AI ONLY for complex/ambiguous commands or questions
    else {
      console.log('ğŸ¤” No direct match - using AI for complex analysis...');
      
      try {
        // Call AI Intent Analyzer
        const apiResponse = await fetch('/api/assistant/intent-analyze', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ command: text }),
        });

        if (apiResponse.ok) {
          const intent = await apiResponse.json();
          console.log('âœ… AI Intent Result:', JSON.stringify(intent, null, 2));
          
          action = intent.action || 'unknown';
          response = intent.arabic_response || 'ØªÙ…Ø§Ù…!';
          
          // Fix confidence if it's not a number
          let confidenceValue = intent.confidence;
          if (typeof confidenceValue !== 'number') {
            confidenceValue = 0.85; // Default
          }
          
          const confidence = Math.round(confidenceValue * 100);
          console.log(`ğŸ¯ AI Confidence: ${confidence}%`);
          
          if (confidence < 70 && confidence > 0) {
            console.warn(`âš ï¸ Low AI confidence (${confidence}%) - LUCA might misunderstand`);
            // Add a confirmation in response if low confidence
            if (confidence < 50) {
              response = `${response} (ÙÙ‡Ù…ØªØ´ Ù…Ù„ÙŠØ­ØŸ)`; // Did I understand correctly?
            }
          }
          
          // Special handling for questions vs commands
          if (action === 'unknown') {
            // Try AI Chat for general questions
            console.log('ğŸ¤” AI says unknown, trying Q&A...');
            const chatResponse = await fetch('/api/assistant/chat', {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({ 
                question: text,
                language: 'ar-TN'
              }),
            });

            if (chatResponse.ok) {
              const data = await chatResponse.json();
              response = data.answer || 'Ù…Ø¹Ù„ÙŠØ´ØŒ Ù…Ø§ ÙÙ‡Ù…ØªØ´.';
              action = 'ai_answer';
            } else {
              response = 'Ù…Ø¹Ù„ÙŠØ´ØŒ Ù…Ø§ ÙÙ‡Ù…ØªØ´. Ù‚Ù„Ù‘ÙŠ "help" Ø¨Ø§Ø´ Ù†ÙˆØ±Ù‘ÙŠÙƒ Ø§Ù„Ø£ÙˆØ§Ù…Ø±.';
            }
          }
        } else {
          console.error('âŒ AI Intent API failed');
          response = 'Ù…Ø¹Ù„ÙŠØ´ØŒ ØµØ§Ø± Ù…Ø´ÙƒÙ„. Ø¹Ø§ÙˆØ¯ Ù…Ù† ÙØ¶Ù„Ùƒ.';
        }
      } catch (error) {
        console.error('âŒ AI Intent analysis error:', error);
        response = 'Ù…Ø¹Ù„ÙŠØ´ØŒ ØµØ§Ø± Ù…Ø´ÙƒÙ„. Ø¹Ø§ÙˆØ¯ Ù…Ù† ÙØ¶Ù„Ùƒ.';
      }
    }

    // Execute the action
    if (action !== 'unknown') {
      console.log('ğŸ”§ Executing action:', action);
      await this.executeAction(action);
    }

    // Speak the response
    console.log('ğŸ’¬ LUCA will say:', response);
    await this.speak(response);
    
    if (this.onResponseCallback) {
      this.onResponseCallback(response);
    }

    // ğŸ” Continue listening
    console.log('ğŸ‘‚ LUCA is still listening for your next command...');
  }

  // ğŸ­ Set LUCA's mode
  private setMode(mode: LucaMode): void {
    this.currentMode = mode;
    console.log('ğŸ­ LUCA Mode changed to:', mode);
  }

  // ğŸ“ Get current mode
  public getCurrentMode(): LucaMode {
    return this.currentMode;
  }

  private async executeAction(action: string, parameters?: Record<string, any>): Promise<void> {
    console.log('ğŸ”§ Executing action:', action, parameters);

    switch (action) {
      case 'tell_time':
        console.log('â° Telling time');
        break;
      
      case 'stop_listening':
        console.log('ğŸ›‘ Stopping LUCA by user request');
        break;
        
      case 'open_mail':
        if (typeof window !== 'undefined') {
          window.location.href = '/mail';
        }
        break;
      
      case 'open_calendar':
        if (typeof window !== 'undefined') {
          window.location.href = '/calendar';
        }
        break;
      
      case 'open_tasks':
        if (typeof window !== 'undefined') {
          window.location.href = '/tasks';
        }
        break;
      
      case 'open_notes':
        if (typeof window !== 'undefined') {
          window.location.href = '/notes';
        }
        break;
      
      case 'open_dashboard':
        if (typeof window !== 'undefined') {
          window.location.href = '/dashboard';
        }
        break;
      
      case 'open_education':
        if (typeof window !== 'undefined') {
          window.location.href = '/education';
        }
        break;
      
      case 'open_memory':
        if (typeof window !== 'undefined') {
          window.location.href = '/memory';
        }
        break;
      
      case 'open_meetings':
        if (typeof window !== 'undefined') {
          window.location.href = '/meetings';
        }
        break;
      
      case 'open_team':
        if (typeof window !== 'undefined') {
          window.location.href = '/team';
        }
        break;
      
      case 'open_projects':
        if (typeof window !== 'undefined') {
          window.location.href = '/projects';
        }
        break;
      
      case 'email_compose_mode':
        console.log('ğŸ“§ Switching to email composition mode');
        // Stay in email mode, waiting for dictation
        break;
      
      case 'email_dictation':
        console.log('ğŸ“ Capturing email text');
        // Here you would capture and store the dictated text
        break;
      
      case 'search_mode':
        console.log('ğŸ” Switching to search mode');
        break;
      
      case 'perform_search':
        console.log('ğŸ” Performing search');
        // Trigger search functionality
        if (typeof window !== 'undefined') {
          window.dispatchEvent(new CustomEvent('luca:open-search'));
        }
        break;
      
      case 'help':
        console.log('â“ Showing help');
        break;
      
      case 'ai_answer':
        console.log('ğŸ¤– AI answered a question');
        break;
      
      default:
        console.warn('Unknown action:', action);
    }
  }

  public async speak(text: string): Promise<void> {
    console.log('ğŸ¯ speak() called with text:', text);
    console.log('ğŸ™ï¸ Current TTS Provider:', cloudTTS.getCurrentProvider());
    
    if (this.onStatusChangeCallback) {
      this.onStatusChangeCallback('speaking');
    }

    try {
      // Use Cloud TTS Service (supports Azure Tunisian voice, ElevenLabs, or Browser fallback)
      console.log('ğŸŒ Using Cloud TTS...');
      await cloudTTS.speak(text, 'ar-TN');
      console.log('âœ… speak() completed successfully');
    } catch (error) {
      console.error('âŒ Speech error in speak():', error);
      // Final fallback to browser TTS
      console.log('ğŸ”„ Final fallback to browser TTS');
      await this.speakWithBrowserTTS(text);
    } finally {
      if (this.onStatusChangeCallback) {
        this.onStatusChangeCallback('listening');
      }
    }
  }

  private async speakWithEdgeTTS(text: string): Promise<void> {
    // Call Edge TTS API
    const response = await fetch('/api/tts/edge', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        text,
        voice: 'ar-TN-HediaNeural', // Tunisian female voice
      }),
    });

    if (!response.ok) {
      throw new Error('Edge TTS failed');
    }

    const audioBlob = await response.blob();
    const audioUrl = URL.createObjectURL(audioBlob);
    const audio = new Audio(audioUrl);
    
    return new Promise((resolve) => {
      audio.onended = () => {
        URL.revokeObjectURL(audioUrl);
        resolve();
      };
      audio.play();
    });
  }

  private speakWithBrowserTTS(text: string): Promise<void> {
    return new Promise((resolve) => {
      if (typeof window === 'undefined' || !window.speechSynthesis) {
        console.error('âŒ Speech synthesis not available');
        resolve();
        return;
      }

      console.log('ğŸ—£ï¸ LUCA is speaking:', text);
      
      // Get voices and wait if not loaded
      let voices = window.speechSynthesis.getVoices();
      
      if (voices.length === 0) {
        console.warn('â³ Voices not loaded yet, waiting...');
        // Wait for voices to load
        window.speechSynthesis.onvoiceschanged = () => {
          voices = window.speechSynthesis.getVoices();
          console.log('âœ… Voices loaded:', voices.length);
          this.speakWithBrowserTTS(text).then(resolve); // Retry
        };
        
        // Trigger voice loading
        window.speechSynthesis.getVoices();
        
        // Timeout fallback
        setTimeout(() => {
          voices = window.speechSynthesis.getVoices();
          if (voices.length === 0) {
            console.error('âŒ Voices still not loaded after wait, speaking anyway...');
          }
        }, 1000);
        
        return;
      }

      console.log('ğŸ™ï¸ Available voices:', voices.length);
      console.log('ğŸ“‹ Voice list:', voices.map(v => `${v.name} (${v.lang})`).join(', '));
      
      // Create the utterance object FIRST
      const utterance = new SpeechSynthesisUtterance(text);
      
      // Find and set voice - prioritize voices that actually work
      const arabicVoice = voices.find(v => 
        v.lang.startsWith('ar') || 
        v.lang === 'ar-TN' ||
        v.lang === 'ar-SA' ||
        v.lang === 'ar-EG'
      );
      
      if (arabicVoice) {
        console.log('âœ… Using Arabic voice:', arabicVoice.name, arabicVoice.lang);
        utterance.voice = arabicVoice;
        utterance.lang = arabicVoice.lang;
      } else {
        // FORCE use first available voice (guaranteed to work)
        console.warn('âš ï¸ No Arabic voice found, using FIRST AVAILABLE voice to speak Arabic text');
        const firstVoice = voices[0];
        if (firstVoice) {
          console.log('ğŸ™ï¸ Forcing voice:', firstVoice.name, firstVoice.lang);
          utterance.voice = firstVoice; // This is the KEY fix!
          utterance.lang = firstVoice.lang; // Use the voice's native language
        } else {
          utterance.lang = 'en-US'; // Absolute fallback
        }
      }
      
      utterance.rate = 0.9;
      utterance.pitch = 1.0;
      utterance.volume = 1.0;
      
      console.log('ğŸ”§ Utterance config:', {
        text: text.substring(0, 30) + '...',
        voice: utterance.voice?.name,
        lang: utterance.lang,
        rate: utterance.rate,
        volume: utterance.volume
      });

      utterance.onstart = () => {
        console.log('ğŸ”Š Speech started - AUDIO SHOULD BE PLAYING NOW!');
      };

      utterance.onend = () => {
        console.log('âœ… Speech ended - audio finished');
        resolve();
      };
      
      utterance.onerror = (event) => {
        console.error('âŒ Speech error:', event);
        console.error('âŒ Error details:', {
          error: event.error,
          type: event.type
        });
        resolve();
      };

      console.log('ğŸ¤ Calling speechSynthesis.speak()...');
      console.log('ğŸ¤ Queue before speak:', window.speechSynthesis.pending);
      window.speechSynthesis.speak(utterance);
      
      // Verify it's speaking
      setTimeout(() => {
        console.log('ğŸ“Š Speaking status:', window.speechSynthesis.speaking);
        console.log('ğŸ“Š Pending status:', window.speechSynthesis.pending);
        console.log('ğŸ“Š Paused status:', window.speechSynthesis.paused);
      }, 100);
    });
  }

  public start(): void {
    if (!this.recognition) {
      console.error('âŒ Speech recognition not available in this browser');
      alert('âš ï¸ Speech recognition not supported in your browser. Please use Chrome or Edge.');
      return;
    }

    if (this.isListening) {
      console.log('âœ… LUCA already listening');
      return;
    }

    try {
      console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
      console.log('ğŸ¤– LUCA AI VOICE ASSISTANT - ChatGPT Mode');
      console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
      console.log('ğŸ¤ ASR: Web Speech API (Streaming)');
      console.log('ğŸ§  AI: Google Gemini 1.5 Flash');
      console.log('ğŸ™ï¸ Language: Standard Arabic (ar-SA)');
      console.log('ğŸ” Mode: STREAMING CONTINUOUS');
      console.log('â±ï¸ Silence threshold: ' + this.silenceThreshold + 'ms');
      console.log('ğŸ“Š Alternatives: 5 (confidence tracking)');
      console.log('ğŸ¯ Wake words: "Ù„ÙˆÙƒØ§", "LUCA", "Ahla Beleh"');
      console.log('ğŸ›‘ Stop command: "LUCA stop" / "LUCA Ø®Ù„Ø§Øµ"');
      console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
      console.log('ğŸ¬ PIPELINE: Mic â†’ ASR â†’ AI Analysis â†’ Action â†’ TTS');
      console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
      
      this.continuousMode = true; // Enable continuous listening
      this.recognition.start();
      this.isListening = true;
      
      if (this.onStatusChangeCallback) {
        this.onStatusChangeCallback('listening');
      }
      
      // Show user notification
      if (typeof window !== 'undefined') {
        setTimeout(() => {
          console.log('âœ… LUCA STREAMING MODE ACTIVE');
          console.log('ğŸ’¡ Speak naturally - AI understands ALL variations!');
          console.log('ğŸ¯ Say "Ù„ÙˆÙƒØ§ [command]" - LUCA will respond instantly');
          console.log('âš¡ Examples: "Ù„ÙˆÙƒØ§ Ø§Ù„Ø¯ÙŠØ³Ø¨ÙˆØ±Ø¯" "Ù„ÙˆÙƒØ§ Ø§ÙŠÙ…ÙŠÙ„" "Ù„ÙˆÙƒØ§ ØªØ³ÙƒØ§Øª"');
        }, 500);
      }
    } catch (error: any) {
      if (error.name === 'InvalidStateError') {
        console.log('âœ… LUCA already started');
        this.isListening = true;
      } else if (error.name === 'NotAllowedError') {
        console.error('âŒ MICROPHONE PERMISSION DENIED!');
        alert('ğŸ¤ CRITICAL: Please allow microphone access for LUCA to work!\n\nClick the ğŸ”’ icon in your browser address bar and enable microphone.');
      } else {
        console.error('âŒ Failed to start listening:', error);
        alert(`âŒ Error starting LUCA: ${error.message}\n\nTry refreshing the page or check your microphone.`);
      }
    }
  }

  public stop(): void {
    if (!this.recognition || !this.isListening) return;

    try {
      this.continuousMode = false; // Disable auto-restart
      this.recognition.stop();
      this.isListening = false;
      this.setMode('idle');
      console.log('ğŸ”‡ LUCA stopped listening');
      console.log('ğŸ›‘ Continuous mode disabled');
      
      if (this.onStatusChangeCallback) {
        this.onStatusChangeCallback('idle');
      }
    } catch (error) {
      console.error('Failed to stop listening:', error);
    }
  }

  public toggle(): void {
    if (this.isListening) {
      this.stop();
    } else {
      this.start();
    }
  }

  public getStatus(): boolean {
    return this.isListening;
  }

  // Event listeners
  public onWakeWord(callback: () => void): void {
    this.onWakeWordCallback = callback;
  }

  public onCommand(callback: (command: string) => void): void {
    this.onCommandCallback = callback;
  }

  public onResponse(callback: (response: string) => void): void {
    this.onResponseCallback = callback;
  }

  public onStatusChange(callback: (status: 'idle' | 'listening' | 'processing' | 'speaking') => void): void {
    this.onStatusChangeCallback = callback;
  }

  public destroy(): void {
    this.clearSilenceTimer();
    this.stop();
    if (this.recognition) {
      this.recognition.onresult = null;
      this.recognition.onerror = null;
      this.recognition.onend = null;
      this.recognition.onaudiostart = null;
      this.recognition.onaudioend = null;
      this.recognition.onsoundstart = null;
      this.recognition.onsoundend = null;
      this.recognition.onspeechstart = null;
      this.recognition.onspeechend = null;
      this.recognition = null;
    }
    console.log('ğŸ—‘ï¸ LUCA destroyed and cleaned up');
  }

  // ğŸ¯ Get performance stats
  public getStats(): {
    isListening: boolean;
    mode: LucaMode;
    lastSpeechTime: number;
    isBusy: boolean;
    continuousMode: boolean;
  } {
    return {
      isListening: this.isListening,
      mode: this.currentMode,
      lastSpeechTime: this.lastSpeechTime,
      isBusy: this.isProcessingCommand,
      continuousMode: this.continuousMode,
    };
  }
}

// Singleton instance
let lucaInstance: LucaVoiceAssistant | null = null;

export function getLucaAssistant(): LucaVoiceAssistant {
  if (!lucaInstance && typeof window !== 'undefined') {
    lucaInstance = new LucaVoiceAssistant();
  }
  return lucaInstance!;
}

